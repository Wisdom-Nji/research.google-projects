# -*- coding: utf-8 -*-
"""Word Vector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v2cEZ_IxUVefq_DMX2IF91dBMXKPfic9
"""

import spacy
import pickle
from sklearn import svm

nlp = spacy.load("en_core_web_md")

class Category:
  URGENT = "URGENT" 
  RESULTS = "RESULT"
  QUESTIONS = "QUESTION"
  STATEMENTS = "STATEMENT"

# Data = { URGENT or RESULT}
# Upload Question from data files, which allow for more data to be added to the entire mix
train_x = ['The test was positive', 'Nobody got sick', 'We do not have TB', 'You results are available', "I'm not sick", "I am not negative"]
train_x1 = ['Please send help', 'I need someone right now', 'Her water just broke', "i've been shot"]
train_y = [Category.RESULTS, Category.RESULTS, Category.RESULTS, Category.RESULTS, Category.RESULTS, Category.RESULTS]
train_y1 = [Category.URGENT, Category.URGENT, Category.URGENT, Category.URGENT]

train_x += train_x1 
train_y += train_y1
print( len(train_y), ":", train_y )

# Data = {Question or Statement}
train_questions = ['What drug is this?', 'would I have to pay?', 'is this free?', 'can this not be for free?', 'should i come back later?', 'am I tired?', "could we know for sure?", "should I ask?", "could I have TB?"]
train_label_statements = [Category.STATEMENTS, Category.STATEMENTS, Category.STATEMENTS, Category.STATEMENTS, Category.STATEMENTS, Category.STATEMENTS]
train_label_statements1 = [Category.STATEMENTS, Category.STATEMENTS, Category.STATEMENTS, Category.STATEMENTS]
train_label_questions = [Category.QUESTIONS, Category.QUESTIONS, Category.QUESTIONS, Category.QUESTIONS, Category.QUESTIONS, Category.QUESTIONS, Category.QUESTIONS, Category.QUESTIONS, Category.QUESTIONS]

train_sq_data = train_label_statements + train_label_statements1 + train_label_questions

train_cat_data = []
train_cat_data += train_x + train_questions

# training cat data
docs = [nlp(text) for text in train_x]
train_x_word_vectors = [x.vector for x in docs]

# training sq data
docs = [nlp(text) for text in train_cat_data]
train_x_word_vectors_for_questions = [x.vector for x in docs]

clf_svm_wv = svm.SVC(kernel='linear')
clf_svm_wv.fit(train_x_word_vectors, train_y)

# Training for Questions or statements
clf_svm_wv_sq = svm.SVC(kernel='linear')
clf_svm_wv_sq.fit(train_x_word_vectors_for_questions, train_sq_data)

# Using Pickle to save the file
cat_fit_dump = pickle.dumps( clf_svm_wv)
print( "pickle dump:", cat_fit_dump )
# TODO: write this to file
# TODO: read the file using: https://stackoverflow.com/a/35068080

test_x = ["Can I get tested?"]
test_docs = [nlp(text) for text in test_x]

test_x_word_vectors = [x.vector for x in test_docs]

print("Statement|Question:", clf_svm_wv_sq.predict( test_x_word_vectors ))
print("Urgent|Results:", clf_svm_wv.predict( test_x_word_vectors ))
