# -*- coding: utf-8 -*-
"""Word Vector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v2cEZ_IxUVefq_DMX2IF91dBMXKPfic9

python -m spacy download en_core_web_lg
"""

import spacy
import csv
import pickle
import sys
from sklearn import svm


def get_training_data( csvfilename, col_training_data, col_training_data_labels ):
    csvfile = open( csvfilename, "r" )
    csvfile_reader = csv.DictReader( csvfile, delimiter=',' )

    line_counter = 0
    training_data = []
    training_data_labels = []

    for row in csvfile_reader:
        training_data.append( row[col_training_data] )
        training_data_labels.append( row[col_training_data_labels] )

    print(f"$ len(training_data):{len(training_data)}\n$ len(training_data_labels):{len(training_data_labels)}")

    return {"data": training_data, "labels": training_data_labels}


def save_fit_data( fit_dump, filename ):
    writefile = open( filename, "wb")
    pickle.dump( fit_dump, writefile )
    writefile.close()
    print(f">> Trained Data Saved: [{filename}]")

def train( labelled_dataset ):

    # training cat data
    docs = [nlp(text) for text in labelled_dataset["data"]]
    data_word_vectors = [x.vector for x in docs]

    # clf_svm_wv = svm.SVC(kernel='linear')
    clf_svm_wv = svm.SVC(kernel='rbf', verbose=True)
    clf_svm_wv.fit(data_word_vectors, labelled_dataset["labels"])

    return clf_svm_wv

def load_fit_data( filename ):
    readfile = open( filename, 'rb')

    return pickle.load( readfile )

def write_to_csv_file(filename, data):
    with open(DATA_FILENAME, mode='a+') as csvfile:
        csvfile_writer = csv.writer(
            csvfile,
            delimiter=',',
            quotechar='"',
            quoting=csv.QUOTE_NONNUMERIC)
        csvfile_writer.writerow( data )
        print("[+] File saved")

if __name__ == "__main__":
    nlp = spacy.load("en_core_web_md")
    DATASET_FILENAME = "data_gathering/data/dataset.csv"

    if sys.argv[1] == "--train":
        print("(training)$_ ")

        # acquire data
        labelled_dataset = get_training_data(DATASET_FILENAME, "text", "type")

        # train
        clf_svm_wv = train( labelled_dataset )

        # save file
        save_filename = argv[2]
        if not save_filename:   
            save_filename = "trained_savefiles/trained_facts_classifier.obj"
        save_fit_data( clf_svm_wv, save_filename )

    elif sys.argv[1] == "--predict":
        # TODO: This should be able to load the obj rather than just saving it [--load]
        try:
            input_text = sys.argv[2]
            # print(f"(predicting)$_ {input_text}")

            fit_filename = "trained_savefiles/trained_facts_classifier.obj"
            clf_svm_wv = load_fit_data( fit_filename )
            test_input = [ input_text ]
            test_docs = [nlp(text) for text in test_input]
            test_input_vectors = [x.vector for x in test_docs]

            prediction = clf_svm_wv.predict( test_input_vectors )[0]
            # print(f"(prediction)$ ({test_input})_ {clf_svm_wv.predict( test_input_vectors )}")
            print(f"(prediction)$ ({test_input})_ {prediction}")

            save = input(f">> Save? yes|no - [{fit_filename}]: ")
            save = save.lower()

            if save == 'yes':
                write_to_csv_file( DATA_FILENAME, [input_text, prediction] )
            else:
                print(">> exiting..")

            '''
            TODO: make this happen
            if save == "yes":
                write_to_dataset( fit_filename, input_text, prediction )
            '''

        except ValueError as valueError:
            print(valueError)
    else:
        print(">> Usage: --predict <input>|--train")


